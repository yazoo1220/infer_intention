import os
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    AIMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain.schema import (
    AIMessage,
    HumanMessage,
    SystemMessage
)
from langchain.utilities import SerpAPIWrapper
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import WebBaseLoader
from langchain.chains.summarize import load_summarize_chain
from langchain.prompts.chat import ChatPromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
import streamlit as st

def get_top_urls(keyword, k=2):
  '''
  Get top k urls from the search result of the keyword
  '''
  res = search.results(keyword)
  urls = list(map(lambda x: x['link'], res['organic_results'][:k]))
  return urls

def get_summary_by_url(url):
  loader = WebBaseLoader(url)
  docs = loader.load()
  # Split the document into texts
  texts = text_splitter.create_documents([str(docs)])

  # limit the length of the doc to read
  length = len(texts)
  if len(texts) > 3:
    length = 3

  summary_chain = load_summarize_chain(llm, chain_type="map_reduce")
  summary = summary_chain.run(texts[:length])
  return summary

def infer_intention_from_summary(keyword, summary):
  prompt = ChatPromptTemplate.from_messages([(
      "system",
      """
      ã‚ãªãŸã¯SEOã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
      """
      ), (
      "human",
      """
      ã“ã®è¦ç´„ã¯ã‚ã‚‹æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä¸Šä½ã®çµæœã§ã™ã€‚
      ã“ã®å†…å®¹ãŒä¸Šä½ã«æ¥ã¦ã„ã‚‹ã¨ã„ã†ã“ã¨ã‹ã‚‰ã“ã®å†…å®¹ãŒæ¤œç´¢æ„å›³ã‚’æº€è¶³ã•ã›ã‚‹ã‚‚ã®ã¨ä»®å®šã§ãã¾ã™ã€‚
      ã“ã®å†…å®¹ã‹ã‚‰å…ƒã®æ¤œç´¢è€…ã®æ¤œç´¢æ„å›³ã‚’æ¨æ¸¬ã—ã¦ãã ã•ã„ã€‚å…·ä½“çš„ã«ã¯

ã€€ã€€ã€€ æ„å›³ã®ç¨®é¡: Know Go Do Buy ã®å››åˆ†é¡ã®ã©ã‚Œã«å½“ã¦ã¯ã¾ã‚‹ã‹
ã€€ã€€ã€€ å±æ€§:å¹´é½¢å±¤ãƒ»æ³•äººã‹å€‹äººã‹ãƒ»å®¶æ—æ§‹æˆãƒ»äººç”Ÿã®æ®µéšãªã©ï¼‰ã®äººé–“ã‹
      ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—:ã€€è¨˜äº‹ã€€ã‚µãƒ¼ãƒ“ã‚¹ã€€EC ãã®ä»–ãªã©ã«åˆ†é¡
      é¡•åœ¨ãƒ‹ãƒ¼ã‚º: æƒ³å®šèª­è€…ãŒæ—¢ã«æŒã£ã¦ã„ã¦è¨˜äº‹ã‚’èª­ã‚€éš›ã«é ­ã«ç½®ã„ã¦ã„ã‚‹ãƒ‹ãƒ¼ã‚º
      æ½œåœ¨ãƒ‹ãƒ¼ã‚º: æƒ³å®šèª­è€…è‡ªèº«æ„è­˜ã—ã¦ã„ãªã„ãŒã€ä½•ã‹ã®ãã£ã‹ã‘ã§é¡•åœ¨åŒ–ã—ã†ã‚‹ãƒ‹ãƒ¼ã‚º
      ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³: ã©ã‚“ãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã§ä½•ã‚’ç›®çš„ã«ã—ã¦æ¤œç´¢ã—ãŸã‹ã‚’æ¨æ¸¬ã—ã¦ãã ã•ã„ã€‚
      ä¸æº€ç‚¹: ã¾ãŸã“ã®ã‚µã‚¤ãƒˆã®ã©ã®ã‚ˆã†ãªç‚¹ã«ä¸æº€ã‚’æ„Ÿã˜ã‚‹ã‹ã‚‚è§£èª¬ã—ã¦ãã ã•ã„ã€‚

      å…ƒã®æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯ã€Œ{keyword}ã€ã§ã™ã€‚
      å›ç­”ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§è€ƒãˆã‚ˆã†ã€‚
      {input}
      """
      )
      ])
  int_chain = prompt | llm
  intention = int_chain.invoke({"keyword": keyword, "input": summary})
  return intention

def infer_intention_from_keyword(keyword, k=2):
  urls = get_top_urls(keyword, k)
  print('urls are fetched')
  summaries = []
  for url in urls:
    print('summarizing ' + url)
    summary = get_summary_by_url(url)
    summaries.append(summary)
  print(summaries)

  intentions = []
  for summary in summaries:
    intention = infer_intention_from_summary(keyword, summary)
    print(intention)
    intentions.append(intention)

  return intentions


# title
st.title('ğŸ” æ¤œç´¢æ„å›³é€†ç®—ãƒ„ãƒ¼ãƒ«')
st.markdown('æ¤œç´¢çµæœã®ä¸Šä½ã®å†…å®¹ã‚’è¦ç´„ã—ã€æ¤œç´¢è€…ã®æ„å›³ã‚’æ¸¬ã‚‹ãŸã‚ã®è¦ç´ ã‚’æŠ½å‡ºã—ã¾ã™')

# Fetch URLs to analyze
search = SerpAPIWrapper()
query = st.text_input('æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', placeholder='ãƒãƒ³ã‚·ãƒ§ãƒ³ ãƒªãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³')
top_k = st.slider('è¡¨ç¤ºã™ã‚‹çµæœ', 1, 5, 2)

# Create an instance of the RecursiveCharacterTextSplitter
llm = ChatOpenAI(temperature=0, model='gpt-3.5-turbo')
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)

if query:
    query_button = st.button("å®Ÿè¡Œ")

    # session_stateã«responsesã®ãƒªã‚¹ãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆã€æ–°ã—ã„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    if 'all_responses' not in st.session_state:
        st.session_state.all_responses = []

    if query_button or ('download_clicked' in st.session_state and st.session_state.download_clicked):
        with st.spinner("..."):
            if query_button:  # æ–°ã—ã„ã‚¯ã‚¨ãƒªãŒå®Ÿè¡Œã•ã‚ŒãŸå ´åˆã®ã¿responsesã‚’å–å¾—
                new_responses = infer_intention_from_keyword(query, top_k)
                new_responses = [res.content for res in new_responses]
                st.session_state.all_responses.extend(new_responses)

            # å…¨ã¦ã®responsesã‚’è¡¨ç¤º
            content = "\n\n".join(st.session_state.all_responses)
            st.code(content)

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã“ã¨ã‚’session_stateã§ãƒˆãƒ©ãƒƒã‚¯
            if st.download_button("â¬‡ï¸csv", content):
                st.session_state.download_clicked = True
            else:
                st.session_state.download_clicked = False



# def suggest_outline_from_intention(intention):
#   prompt = ChatPromptTemplate.from_messages([(
#       "system",
#       """
#       ã‚ãªãŸã¯SEOã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
#       """
#       ), (
#       "human",
#       """
#       ã“ã®è¦ç´„ã¯ã‚ã‚‹æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ãŠã‘ã‚‹æ¤œç´¢æ„å›³ã‚’åˆ†æã—ãŸã‚‚ã®ã§ã™ã€‚
#       ã“ã®å†…å®¹ã‚’å…ƒã«åŒã˜æ¤œç´¢æ„å›³ã‚’æŒã£ãŸäººãŒæº€è¶³ã™ã‚‹è¨˜äº‹ã®ç›®æ¬¡ã‚’ï¼“ãƒ‘ã‚¿ãƒ¼ãƒ³è€ƒãˆã¦ãã ã•ã„ã€‚
#       è¨˜äº‹ã®å†…å®¹ã¯ä¸‹è¨˜ã®å†…å®¹ã§é™å®šã—ã¾ã™ã€‚
#       - ãƒªãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ãƒªãƒ•ã‚©ãƒ¼ãƒ ã«é–¢ã™ã‚‹ã“ã¨
#       - ãƒãƒ³ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ã“ã¨
#       å›ç­”ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚æ°´å¹³æ€è€ƒã§è€ƒãˆã‚ˆã†ã€‚

#       ###
#       æ¤œç´¢æ„å›³ï¼š
#       {intention}
#       """
#       )
#       ])
#   outline_chain = prompt | llm
#   outline = outline_chain.invoke({"intention": intention})
#   return outline

# st.markdown(suggest_outline_from_intention(str(mansion_res[0])))
